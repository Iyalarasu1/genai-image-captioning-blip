## Prototype Development for Image Captioning Using the BLIP Model and Gradio Framework

### AIM:
To design and deploy a prototype application for image captioning by utilizing the BLIP image-captioning model and integrating it with the Gradio UI framework for user interaction and evaluation.

### PROBLEM STATEMENT:

The challenge is to create an interactive image captioning tool that uses a pretrained BLIP model to generate captions for images uploaded by users. The application should be able to receive an image, pass it through the BLIP model to generate captions, and then display the generated caption to the user in a user-friendly Gradio interface.

### DESIGN STEPS:

#### STEP 1:

Install required libraries like Gradio and BLIP.
Ensure the environment has access to the necessary model files.

#### STEP 2:

Load the BLIP model from a pretrained version available through libraries like transformers or another source.
Ensure that the BLIP model is correctly configured to accept image inputs and generate captions.

#### STEP 3:

Define a simple UI using Gradio, where users can upload an image.
The Gradio interface will display the caption generated by the BLIP model after processing the image.

### PROGRAM:

```
import os
import io
import base64
import json
import requests
from PIL import Image
from dotenv import load_dotenv, find_dotenv
import gradio as gr

# Load environment variables
_ = load_dotenv(find_dotenv())
hf_api_key = os.environ["HF_API_KEY"]
HF_API_ITT_BASE = os.environ["HF_API_ITT_BASE"]


# ---------------------------------------------------------
# Send request to HuggingFace BLIP image captioning endpoint
# ---------------------------------------------------------
def get_completion(base64_str):
    url = HF_API_ITT_BASE

    # ✅ Correct payload format
    payload = {
        "inputs": f"data:image/png;base64,{base64_str}"
    }

    headers = {
        "Authorization": f"Bearer {hf_api_key}",
        "Content-Type": "application/json",
    }

    response = requests.post(url, headers=headers, data=json.dumps(payload))

    try:
        return response.json()
    except:
        return {"error": "Invalid API response (not JSON)"}


# ---------------------------------------------------------
# Convert PIL → Base64
# ---------------------------------------------------------
def image_to_base64_str(pil_image):
    buf = io.BytesIO()
    pil_image.save(buf, format="PNG")
    return base64.b64encode(buf.getvalue()).decode("utf-8")


# ---------------------------------------------------------
# Caption generator function WITH error handling
# ---------------------------------------------------------
def captioner(image):
    try:
        base64_img = image_to_base64_str(image)
        result = get_completion(base64_img)

        # API error response
        if isinstance(result, dict) and "error" in result:
            return "API Error: " + result["error"]

        # CASE 1 — result is a list
        if isinstance(result, list):
            if len(result) > 0 and "generated_text" in result[0]:
                return result[0]["generated_text"]
            return f"Unexpected list format: {result}"

        # CASE 2 — result is a dict
        if isinstance(result, dict):
            if "generated_text" in result:
                return result["generated_text"]
            return f"Unexpected dict format: {result}"

        return f"Unknown response type: {result}"

    except Exception as e:
        return f"Error: {str(e)}"


# ---------------------------------------------------------
# Gradio UI
# ---------------------------------------------------------
gr.close_all()

demo = gr.Interface(
    fn=captioner,
    inputs=[gr.Image(label="Upload image", type="pil")],
    outputs=[gr.Textbox(label="Caption")],
    title="Image Captioning with BLIP",
    description="Upload an image and get an AI-generated caption.",
    allow_flagging="never",
    clear_btn="always",
    examples=[
        ["download (1).jpg"],
        ["download (2).jpg"],
        ["download.jpg"],
    ]
)

demo.launch()

```

### OUTPUT:

<img width="1865" height="861" alt="image" src="https://github.com/user-attachments/assets/7dce3782-c70c-4ec9-b7b7-b216e28cbc18" />



### RESULT:

The application allows users to upload an image through the Gradio interface, where it is processed by the BLIP model to generate a caption. Once the image is processed, the BLIP model produces a concise and relevant description of the image, which is displayed back to the user. For instance, if the uploaded image depicts a dog running in a park, the model may generate a caption such as "A dog running on grass." The system successfully demonstrates the integration of the BLIP image captioning model with Gradio, providing an intuitive and responsive user interface for real-time caption generation. The prototype works effectively for a variety of images, offering accurate and contextually appropriate captions. This application could be expanded further to handle more complex use cases, such as captioning images from specific domains like medical, fashion, or sports.
